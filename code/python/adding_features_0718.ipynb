{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0333b036-3707-4a10-8b31-0300a4e97a4e",
   "metadata": {},
   "source": [
    "# Getting more movie features using TMDB API with a randomly selected sample dataset (N = 50) from `movie_feb2025.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f246fe1b-da59-4868-9668-d0ba6bfda7ac",
   "metadata": {},
   "source": [
    "## Roadmap: What this notebook does  \n",
    "\n",
    "**Goal:** build a clean, feature-rich dataset that can be fed to an LLM / ML model to **predict movie ratings** (initial focus: TMDB `vote_average`).  \n",
    "\n",
    "Below is the step-by-step flow you’ll see in this notebook:\n",
    "\n",
    "| Step | Section | What happens & why |\n",
    "|------|---------------------------|--------------------|\n",
    "| **1** | **Load & Inspect Raw TMDB Data** | Load the original CSV → explore column meanings → quantify missing values. This tells us which features already exist and their data quality. |\n",
    "| **2** | **Split Rated vs Unrated → Train / Test** | Keep only movies with a non-zero TMDB rating. Split them 80 / 20 into `train` and `test`. From the **train** set randomly sample **N = 20** rows that we’ll enrich end-to-end (quick dev loop). |\n",
    "| **3** | **Enrich Movie-level Features** | Via **TMDB movie** endpoints pull extra signal:  `Credits`  · `Keywords`  · `Reviews`  · `Watch Providers`  · `External IDs`. |\n",
    "| **4** | **Enrich Person-level Features** | Use every `actor_*_id` & `crew_*_id` to hit **TMDB people** endpoints. Collect the most predictive fields (chiefly `biography`, plus `gender`, `popularity`, etc.). |\n",
    "| **5** | **Enrich External Features** | **IMDb:** scrape `imdb_rating` / `imdb_votes` / `imdb_metascore`.  **Wikidata:** scrape awards & nominations → `award_count`, `award_names`, `nominated_count`, `nominated_names`. |\n",
    "| **6** | **Feature Cleaning & Transformation** | Convert raw objects to model-friendly text or numeric forms (e.g. genre arrays → “Action, Drama”; language codes → “English”). Drop columns we no longer need. |\n",
    "| **7** | **Column Re-ordering** | Rearrange all features into a logical, human-readable order (IDs & meta first, numerics next, person blocks grouped by actor_1, actor_2, …). |\n",
    "| **8** | **Save Final Dataset** | Export the fully enriched, cleaned CSV that’s ready for finetuning or downstream ML. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda8c2b-4625-4980-9ae1-ac42ab5a58ac",
   "metadata": {},
   "source": [
    "## Load and Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c673faa8-ce39-4bd3-8a88-bb16f3186f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded. Total number of rows: 1032235\n",
      "Actual number of columns: 27\n",
      "   adult                     backdrop_path  \\\n",
      "0  False  /hQ4pYsIbP22TMXOUdSfC2mjWrO0.jpg   \n",
      "1  False  /l94l89eMmFKh7na2a1u5q67VgNx.jpg   \n",
      "2  False  /f2t4JbUvQIjUF5FstG1zZFAp02N.jpg   \n",
      "3  False  /iUUpKunmBN5l8goObADBaFHnxQ8.jpg   \n",
      "4  False                               NaN   \n",
      "\n",
      "                               belongs_to_collection    budget  \\\n",
      "0  {'id': 1382526, 'name': \"Kaurismäki's Proletar...         0   \n",
      "1  {'id': 1382526, 'name': \"Kaurismäki's Proletar...         0   \n",
      "2                                                NaN   4000000   \n",
      "3                                                NaN  21000000   \n",
      "4                                                NaN     42000   \n",
      "\n",
      "                                              genres  \\\n",
      "0  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
      "1  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
      "2                     [{'id': 35, 'name': 'Comedy'}]   \n",
      "3  [{'id': 28, 'name': 'Action'}, {'id': 80, 'nam...   \n",
      "4                [{'id': 99, 'name': 'Documentary'}]   \n",
      "\n",
      "                                    homepage   id    imdb_id origin_country  \\\n",
      "0                                        NaN  2.0  tt0094675         ['FI']   \n",
      "1                                        NaN  3.0  tt0092149         ['FI']   \n",
      "2  https://www.miramax.com/movie/four-rooms/  5.0  tt0113101         ['US']   \n",
      "3                                        NaN  6.0  tt0107286         ['US']   \n",
      "4                     http://lifeinloops.com  8.0  tt0825671         ['AT']   \n",
      "\n",
      "  original_language  ...     revenue runtime  \\\n",
      "0                fi  ...         0.0    73.0   \n",
      "1                fi  ...         0.0    74.0   \n",
      "2                en  ...   4257354.0    98.0   \n",
      "3                en  ...  12136938.0   109.0   \n",
      "4                en  ...         0.0    80.0   \n",
      "\n",
      "                                    spoken_languages    status  \\\n",
      "0  [{'english_name': 'Finnish', 'iso_639_1': 'fi'...  Released   \n",
      "1  [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
      "2  [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
      "3  [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
      "4  [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
      "\n",
      "                                             tagline  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2  Twelve outrageous guests. Four scandalous requ...   \n",
      "3     Don't move. Don't whisper. Don't even breathe.   \n",
      "4                                A Megacities remix.   \n",
      "\n",
      "                              title  video  vote_average  vote_count novelty  \n",
      "0                             Ariel  False         7.104       338.0     NaN  \n",
      "1               Shadows in Paradise  False         7.300       400.0     NaN  \n",
      "2                        Four Rooms  False         5.900      2649.0     NaN  \n",
      "3                    Judgment Night  False         6.500       334.0     NaN  \n",
      "4  Life in Loops (A Megacities RMX)  False         7.362        29.0     NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('movie_feb2025.csv', on_bad_lines='skip', engine='python')\n",
    "df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')\n",
    "\n",
    "print(f\"Successfully loaded. Total number of rows: {len(df)}\")\n",
    "print(f\"Actual number of columns: {df.shape[1]}\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6948360-e733-4727-8d2f-3883c521a6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'backdrop_path', 'belongs_to_collection', 'budget', 'genres',\n",
       "       'homepage', 'id', 'imdb_id', 'origin_country', 'original_language',\n",
       "       'original_title', 'overview', 'popularity', 'poster_path',\n",
       "       'production_companies', 'production_countries', 'release_date',\n",
       "       'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title',\n",
       "       'video', 'vote_average', 'vote_count', 'novelty'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0400785-27bc-40e4-b9f3-458306262e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adult                     object\n",
       "backdrop_path             object\n",
       "belongs_to_collection     object\n",
       "budget                    object\n",
       "genres                    object\n",
       "homepage                  object\n",
       "id                       float64\n",
       "imdb_id                   object\n",
       "origin_country            object\n",
       "original_language         object\n",
       "original_title            object\n",
       "overview                  object\n",
       "popularity               float64\n",
       "poster_path               object\n",
       "production_companies      object\n",
       "production_countries      object\n",
       "release_date              object\n",
       "revenue                  float64\n",
       "runtime                  float64\n",
       "spoken_languages          object\n",
       "status                    object\n",
       "tagline                   object\n",
       "title                     object\n",
       "video                     object\n",
       "vote_average             float64\n",
       "vote_count               float64\n",
       "novelty                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199533f5-f777-4e83-b974-5971091b3f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adult                          0\n",
       "backdrop_path             705978\n",
       "belongs_to_collection    1002926\n",
       "budget                      5956\n",
       "genres                      5956\n",
       "homepage                  905222\n",
       "id                          5956\n",
       "imdb_id                   432462\n",
       "origin_country              5956\n",
       "original_language           5956\n",
       "original_title              7062\n",
       "overview                  178927\n",
       "popularity                  8466\n",
       "poster_path               263570\n",
       "production_companies        7211\n",
       "production_countries        8466\n",
       "release_date              112419\n",
       "revenue                     8466\n",
       "runtime                     8466\n",
       "spoken_languages            8466\n",
       "status                      8466\n",
       "tagline                   879456\n",
       "title                       8475\n",
       "video                       8466\n",
       "vote_average                8466\n",
       "vote_count                  8466\n",
       "novelty                  1032235\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e28bf21-e5e8-4c0c-9184-226cbd846629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       missing_count  missing_percent\n",
      "novelty                      1032235           100.00\n",
      "belongs_to_collection        1002926            97.16\n",
      "homepage                      905222            87.70\n",
      "tagline                       879456            85.20\n",
      "backdrop_path                 705978            68.39\n",
      "imdb_id                       432462            41.90\n",
      "poster_path                   263570            25.53\n",
      "overview                      178927            17.33\n",
      "release_date                  112419            10.89\n",
      "revenue                         8466             0.82\n",
      "title                           8475             0.82\n",
      "vote_count                      8466             0.82\n",
      "popularity                      8466             0.82\n",
      "vote_average                    8466             0.82\n",
      "production_countries            8466             0.82\n",
      "video                           8466             0.82\n",
      "runtime                         8466             0.82\n",
      "spoken_languages                8466             0.82\n",
      "status                          8466             0.82\n",
      "production_companies            7211             0.70\n",
      "original_title                  7062             0.68\n",
      "id                              5956             0.58\n",
      "budget                          5956             0.58\n",
      "origin_country                  5956             0.58\n",
      "genres                          5956             0.58\n",
      "original_language               5956             0.58\n",
      "adult                              0             0.00\n"
     ]
    }
   ],
   "source": [
    "missing_info = pd.DataFrame({\n",
    "    'missing_count': df.isna().sum(),\n",
    "    'missing_percent': (df.isna().sum() / len(df) * 100).round(2)\n",
    "}).sort_values(by='missing_percent', ascending=False)\n",
    "\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4934e5a1-0adb-4b5c-a256-e45be3bf6172",
   "metadata": {},
   "source": [
    "### Drop Entries with Missing TMDB IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d36678-cc75-485c-ba2e-158256e4ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d31731d2-9f7d-4e35-8970-f5b73186a3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12% of movies have an TMDB id of NA\n"
     ]
    }
   ],
   "source": [
    "actural_na_id = (df['id'] == 0).sum()/len(df) * 100\n",
    "print(f\"{actural_na_id:.2f}% of movies have an TMDB id of NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab48dd1-24e9-47b4-ba13-d163843f543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['id'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2704bf-1760-4819-bd0f-b9b775a89a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adult                          0\n",
       "backdrop_path             700022\n",
       "belongs_to_collection     996491\n",
       "budget                         0\n",
       "genres                         0\n",
       "homepage                  898939\n",
       "id                             0\n",
       "imdb_id                   426506\n",
       "origin_country                 0\n",
       "original_language              0\n",
       "original_title                11\n",
       "overview                  172971\n",
       "popularity                  1265\n",
       "poster_path               257614\n",
       "production_companies        1255\n",
       "production_countries        1265\n",
       "release_date              105218\n",
       "revenue                     1265\n",
       "runtime                     1265\n",
       "spoken_languages            1265\n",
       "status                      1265\n",
       "tagline                   872255\n",
       "title                       1274\n",
       "video                       1265\n",
       "vote_average                1265\n",
       "vote_count                  1265\n",
       "novelty                  1025034\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b38e2d4-dcc3-4981-9301-f69d11f3bf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.19% of movies have a vote_average of 0\n"
     ]
    }
   ],
   "source": [
    "percentage_zero = (df['vote_average'] == 0).sum()/len(df) * 100\n",
    "print(f\"{percentage_zero:.2f}% of movies have a vote_average of 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876a4310-ba16-43b7-a9e6-8b5f8995b3e3",
   "metadata": {},
   "source": [
    "### Evaluate Feature Usefulness for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5ff2c3-1540-462f-bc7c-dc45384ff016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       missing_count  missing_percent\n",
      "novelty                      1025034           100.00\n",
      "belongs_to_collection         996491            97.22\n",
      "homepage                      898939            87.70\n",
      "tagline                       872255            85.10\n",
      "backdrop_path                 700022            68.29\n",
      "imdb_id                       426506            41.61\n",
      "poster_path                   257614            25.13\n",
      "overview                      172971            16.87\n",
      "release_date                  105218            10.26\n",
      "revenue                         1265             0.12\n",
      "vote_count                      1265             0.12\n",
      "vote_average                    1265             0.12\n",
      "popularity                      1265             0.12\n",
      "video                           1265             0.12\n",
      "production_companies            1255             0.12\n",
      "production_countries            1265             0.12\n",
      "title                           1274             0.12\n",
      "runtime                         1265             0.12\n",
      "spoken_languages                1265             0.12\n",
      "status                          1265             0.12\n",
      "budget                             0             0.00\n",
      "id                                 0             0.00\n",
      "origin_country                     0             0.00\n",
      "genres                             0             0.00\n",
      "original_title                    11             0.00\n",
      "original_language                  0             0.00\n",
      "adult                              0             0.00\n"
     ]
    }
   ],
   "source": [
    "missing_info = pd.DataFrame({\n",
    "    'missing_count': df.isna().sum(),\n",
    "    'missing_percent': (df.isna().sum() / len(df) * 100).round(2)\n",
    "}).sort_values(by='missing_percent', ascending=False)\n",
    "\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df69372e-2c14-4ebf-a214-bb2a0448ba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.03% of movies have a budget of 0\n"
     ]
    }
   ],
   "source": [
    "df['budget'] = pd.to_numeric(df['budget'], errors='coerce')\n",
    "actural_na_budget = (df['budget'] == 0).sum()/len(df) * 100\n",
    "print(f\"{actural_na_budget:.2f}% of movies have a budget of 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca3dd222-7a90-4a6f-a518-f405e460d534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.13% of movies have a genres of NA\n"
     ]
    }
   ],
   "source": [
    "actural_na_genres = (df['genres'] == '[]').sum()/len(df) * 100\n",
    "print(f\"{actural_na_genres:.2f}% of movies have a genres of NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62c7acba-e309-496e-bd10-00848cb33fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00% of movies have a popularity of 0\n"
     ]
    }
   ],
   "source": [
    "actural_na_popularity = (df['popularity'] == '0').sum()/len(df) * 100\n",
    "print(f\"{actural_na_popularity:.2f}% of movies have a popularity of 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02f1a93a-a63f-4602-99d3-2fc6576f2e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.07% of movies have a production_companies of NA\n"
     ]
    }
   ],
   "source": [
    "actural_na_production_companies = (df['production_companies'] == '[]').sum()/len(df) * 100\n",
    "print(f\"{actural_na_production_companies:.2f}% of movies have a production_companies of NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e51617-c480-4b12-93dc-337586519be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.56% of movies have a production_countries of NA\n"
     ]
    }
   ],
   "source": [
    "actural_na_production_countries = (df['production_countries'] == '[]').sum()/len(df) * 100\n",
    "print(f\"{actural_na_production_countries:.2f}% of movies have a production_countries of NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7140aab8-34b8-45dd-a36e-6aa67a30835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.59% of movies have a revenue of 0\n"
     ]
    }
   ],
   "source": [
    "actural_na_revenue = (df['revenue'] == 0).sum()/len(df) * 100\n",
    "print(f\"{actural_na_revenue:.2f}% of movies have a revenue of 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86eeb2ee-0d20-4d5a-af1f-4016490314ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.23% of movies have a runtime of 0\n"
     ]
    }
   ],
   "source": [
    "actural_na_runtime = (df['runtime'] == 0).sum()/len(df) * 100\n",
    "print(f\"{actural_na_runtime:.2f}% of movies have a runtime of 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62a361b7-19d5-43c6-ab34-6d12b9352d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.75% of movies have a spoken_languages of NA\n"
     ]
    }
   ],
   "source": [
    "actural_na_spoken_languages = (df['spoken_languages'] == '[]').sum()/len(df) * 100\n",
    "print(f\"{actural_na_spoken_languages:.2f}% of movies have a spoken_languages of NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73d52c3a-bcb8-4949-ae36-2f70e3fadc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.19% of movies have a vote_average of 0\n"
     ]
    }
   ],
   "source": [
    "actural_na_vote_average = (df['vote_average'] == 0).sum()/len(df) * 100\n",
    "print(f\"{actural_na_vote_average:.2f}% of movies have a vote_average of 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41f4e784-2240-49f1-a55a-3c0bfb6cb4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.16% of movies have a vote_count of 0\n"
     ]
    }
   ],
   "source": [
    "actural_na_vote_count = (df['vote_count'] == 0).sum()/len(df) * 100\n",
    "print(f\"{actural_na_vote_count:.2f}% of movies have a vote_count of 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f2dbb-d82b-4ae6-a298-c7772f7b413f",
   "metadata": {},
   "source": [
    "### Overview of Current Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e422c7c-f594-4061-a405-e11d4c55d350",
   "metadata": {},
   "source": [
    "Based on the [TMDB API documentation MOVIES - Details](https://developer.themoviedb.org/reference/movie-details), the following introduces the current dataset columns, their meaning, missing rate, and whether they are useful for predicting.\n",
    "\n",
    "`adult`: 0% missing. Defaults to False. However, some movies may be incorrectly marked as non-adult due to unavailable data. Interpret with caution.\n",
    "\n",
    "`backdrop_path`: 68.21% missing. Although visual feature are not needed for training, its presence may correlate with a movie’s rating. Can be transformed into a binary feature.\n",
    "\n",
    "`belongs_to_collection`: 97.14% missing. Only a small percentage of movies belong to a collection, but its presence may correlate with a movie’s rating. May be useful if cleaned.\n",
    "\n",
    "`budget`: 0% missing. Defaults to 0. 94.03% are zeros, which often indicates unavailable data rather than an actual zero budget. Interpret with caution.\n",
    "\n",
    "`genres`: 28.19% actual missing. May be useful if cleaned.\n",
    "\n",
    "`homepage`: 87.62% missing. While the webpage content is not used for training, the presence of a homepage may correlate with a movie’s rating. Can be transformed into a binary feature.\n",
    "\n",
    "`id`: 0% missing after cleaning. This is the unique identifier for each movie in the TMDB database.\n",
    "\n",
    "`imdb_id`: 41.56% missing. While the IMDB content is not used for training, the presence of it may correlate with a movie’s rating. \n",
    "\n",
    "`origin_country`: 0% missing. This feature may correlate with a movie’s rating.\n",
    "\n",
    "`original_language`: 0 missing. This feature may correlate with a movie’s rating.\n",
    "\n",
    "`original_title`: 0.11% missing. This feature may reflect cultural or regional factors that influence ratings.\n",
    "\n",
    "`overview`: 16.85% missing. This is a key input feature for training and predicting ratings.\n",
    "\n",
    "`popularity`: 0.24% missing. This is a dynamic metric provided by TMDB, calculated based on factors such as number of votes, views, favorites, watchlists, release date, and previous popularity scores.\n",
    "\n",
    "Since it combines several other variables already present in the dataset (e.g. release_date), it may introduce **multicollinearity** issues if used together with them. Use with caution.\n",
    "\n",
    "`poster_path`: 25.10% missing. Although visual feature are not needed for training, its presence may correlate with a movie’s rating. Can be transformed into a binary feature.\n",
    "\n",
    "`production_companies`: 53.07% actual missing. May be useful if cleaned.\n",
    "\n",
    "`production_countries`: 38.56% actual missing. May be useful if cleaned.\n",
    "\n",
    "`release_date`: 10.37% missing. This feature may correlate with a movie’s rating.\n",
    "\n",
    "`revenue`: 0.24% missing, but 97.59% are zeros, which often indicates unavailable data rather than an actual zero revenue. Interpret with caution.\n",
    "\n",
    "`runtime`: 23.23% actual missing. This feature may correlate with a movie’s rating.\n",
    "\n",
    "`spoken_languages`: 35.75% actual missing. May be useful if cleaned.\n",
    "\n",
    "`status`: 0.12% missing. Categorical (e.g., Released). Could be relevant to ratings.\n",
    "\n",
    "`tagline`: 85.11% missing. Optional marketing line. It may carry signal for well-marketed films.\n",
    "\n",
    "`title`: 0.25% missing. Some of the movies have english tranlated title, some of them don't. It could have affect the potential rating of the movie.\n",
    "\n",
    "`video`: 0.24% missing. Defaults to false. It could have affect the potential rating of the movie.\n",
    "\n",
    "`vote_average`: 63.19% missing. Defaults to 0 when unrated. This is a target variable for prediction.\n",
    "\n",
    "`vote_count`: 63.16% missing. Defaults to 0 when unrated. This is another target variable for prediction.\n",
    "\n",
    "Note: Image-related features such as `backdrop_path` and `poster_path` are not full URLs. To view the actual image, prepend the path with https://image.tmdb.org/t/p/original/ according to [TMDB's image guide](https://developer.themoviedb.org/docs/image-basics).  \n",
    "\n",
    "Example:  \n",
    "https://image.tmdb.org/t/p/original/hQ4pYsIbP22TMXOUdSfC2mjWrO0.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75d650-fe8b-4839-b43c-d900eaeaf173",
   "metadata": {},
   "source": [
    "## Split the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba314e7e-e579-4fcd-b943-779b4ef2e0e0",
   "metadata": {},
   "source": [
    "**63.19%** of the movies in the current dataset have a `vote_average` of zero on TMDB.\n",
    "\n",
    "Since our goal is to build a predictive model that estimates user ratings based on existing movie features, we only retain movies with valid ratings (vote_average ≠ 0) for model training and evaluation.\n",
    "\n",
    "The dataset is therefore divided into two subsets:\n",
    "\n",
    "- Unrated movies (vote_average == 0): These are excluded from model training but can later be used as input for prediction.\n",
    "\n",
    "- Rated movies (vote_average ≠ 0): These form the basis of our supervised machine learning task. \n",
    "\n",
    "We further split the Rated movies subset as follows:\n",
    "- **80%** for the training dataset\n",
    "- **20%** for the test dataset\n",
    "\n",
    "We randomly draw a small sample of N = 10 movies from the training set and use them to run the code that gathers additional movie features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b467458f-6062-4791-843b-366d8a535730",
   "metadata": {},
   "outputs": [],
   "source": [
    "unrated = df[df['vote_average'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05eafda0-00ab-457b-b4c5-e2ca358356af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rated = df[df['vote_average'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8d63d8b-8641-4012-aaeb-7738af4e9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(rated, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "260fc74a-cefc-4382-ba99-627e736241c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train.sample(n=49, random_state=42)\n",
    "specific_row = train[train[\"id\"] == 238]\n",
    "sample = pd.concat([sample, specific_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24108c0-807b-479b-bd6d-ee21ee98052e",
   "metadata": {},
   "source": [
    "*The Godfather* (ID: 238) is intentionally included in the sample dataset, as it provides complete entries across all relevant features, such as `reviews_TMDB` and `imdb_metascore`, which are often missing in less popular titles. It helps improve the robustness of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac1131df-c47b-4371-9ac5-f2c17b26ac20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>original_language</th>\n",
       "      <th>...</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>novelty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>/eHSemCAEY6TyWO7r1erblh7Xgmw.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1084823.0</td>\n",
       "      <td>tt14837634</td>\n",
       "      <td>['GB']</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Is anything missing?</td>\n",
       "      <td>A Phone Call</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>/tMFMMFXGOC6nQIuDSy3ihThRNgk.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'id': 99, 'name': 'Documentary'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>801172.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['FR', 'CH']</td>\n",
       "      <td>fr</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'english_name': 'French', 'iso_639_1': 'fr',...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cyberbully, When the Haters Rise Up</td>\n",
       "      <td>False</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1175181.0</td>\n",
       "      <td>tt1163322</td>\n",
       "      <td>['AU']</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Taxi!</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>/cjuwqee9OOY9btzf4OO0WiF2f63.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'id': 99, 'name': 'Documentary'}, {'id': 107...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>985789.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['US']</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The English Civil Wars</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'id': 27, 'name': 'Horror'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1305928.0</td>\n",
       "      <td>tt16408474</td>\n",
       "      <td>['US']</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Cult</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                     backdrop_path belongs_to_collection  budget  \\\n",
       "0  False  /eHSemCAEY6TyWO7r1erblh7Xgmw.jpg                   NaN  1000.0   \n",
       "1  False  /tMFMMFXGOC6nQIuDSy3ihThRNgk.jpg                   NaN     0.0   \n",
       "2  False                               NaN                   NaN     0.0   \n",
       "3  False  /cjuwqee9OOY9btzf4OO0WiF2f63.jpg                   NaN     0.0   \n",
       "4  False                               NaN                   NaN     0.0   \n",
       "\n",
       "                                              genres homepage         id  \\\n",
       "0                      [{'id': 18, 'name': 'Drama'}]      NaN  1084823.0   \n",
       "1                [{'id': 99, 'name': 'Documentary'}]      NaN   801172.0   \n",
       "2                                                 []      NaN  1175181.0   \n",
       "3  [{'id': 99, 'name': 'Documentary'}, {'id': 107...      NaN   985789.0   \n",
       "4                     [{'id': 27, 'name': 'Horror'}]      NaN  1305928.0   \n",
       "\n",
       "      imdb_id origin_country original_language  ... revenue runtime  \\\n",
       "0  tt14837634         ['GB']                en  ...     0.0     5.0   \n",
       "1         NaN   ['FR', 'CH']                fr  ...     0.0     0.0   \n",
       "2   tt1163322         ['AU']                en  ...     0.0    72.0   \n",
       "3         NaN         ['US']                en  ...     0.0    78.0   \n",
       "4  tt16408474         ['US']                en  ...     0.0    90.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0  [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
       "1  [{'english_name': 'French', 'iso_639_1': 'fr',...  Released   \n",
       "2                                                 []  Released   \n",
       "3                                                 []  Released   \n",
       "4  [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
       "\n",
       "                tagline                                title  video  \\\n",
       "0  Is anything missing?                         A Phone Call  False   \n",
       "1                   NaN  Cyberbully, When the Haters Rise Up  False   \n",
       "2                   NaN                                Taxi!  False   \n",
       "3                   NaN               The English Civil Wars   True   \n",
       "4                   NaN                             The Cult  False   \n",
       "\n",
       "   vote_average  vote_count novelty  \n",
       "0          10.0         1.0     NaN  \n",
       "1           6.8         2.0     NaN  \n",
       "2           3.5         1.0     NaN  \n",
       "3          10.0         1.0     NaN  \n",
       "4           8.0         7.0     NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df25a735-a51d-49cd-b1d9-afaa69bfaff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32610afe-3d8e-49be-9d7a-859c628b0948",
   "metadata": {},
   "source": [
    "## Enrich Movie-level Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85943eb0-8d02-44ff-bb8c-39b46add2286",
   "metadata": {},
   "source": [
    "For each movie, the following TMDB API endpoints were used to extract additional metadata and enrich the dataset:\n",
    "\n",
    "`Credits`: cast and crew details\n",
    "\n",
    "`Keywords`: thematic tags and topics\n",
    "\n",
    "`Reviews`: short user reviews with author info\n",
    "\n",
    "`Watch Providers`: platforms where the movie can be streamed or bought\n",
    "\n",
    "`External IDs`: IMDb, Wikidata, Facebook, Instagram, Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9f45e-619a-49f2-ae43-b2d864623ba1",
   "metadata": {},
   "source": [
    "### Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b889b7-e998-4e61-9686-419fac4f47de",
   "metadata": {},
   "source": [
    "Based on the [TMDB API documentation for movie credits](https://developer.themoviedb.org/reference/movie-credits), the following variables were extracted and appended to the dataset:\n",
    "\n",
    "- `cast_count`: number of cast members  \n",
    "- `crew_count`: number of crew members  \n",
    "- `cast`: full JSON object containing cast details  \n",
    "- `crew`: full JSON object containing crew details  \n",
    "\n",
    "Each object inside `cast` and `crew` contains structured attributes such as:\n",
    "\n",
    "- `adult`, `gender`, `id`, `known_for_department`, `name`, `original_name`, `popularity`, `profile_path`, `credit_id`  \n",
    "- (cast only): `cast_id`, `character`, `order`  \n",
    "- (crew only): `department`, `job`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de59bc2f-3535-4771-9c77-5015e759c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Load the sample dataset containing movie IDs\n",
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "# API credentials\n",
    "api_key = \"7b4782c9b0a5abfc789b2b79cfab2601\"\n",
    "bearer_token = \"eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI3YjQ3ODJjOWIwYTVhYmZjNzg5YjJiNzljZmFiMjYwMSIsIm5iZiI6MTc0Mzc1NDE0Mi43NjQ5OTk5LCJzdWIiOiI2N2VmOTM5ZTBjNzkxYmViNTdhY2Y1YWUiLCJzY29wZXMiOlsiYXBpX3JlYWQiXSwidmVyc2lvbiI6MX0.2FmX4__p3XQQi5IagAJ1Csa-3WvL67-msP6158CbsHs\"\n",
    "\n",
    "# Prepare empty lists for new columns\n",
    "cast_count_list = []\n",
    "crew_count_list = []\n",
    "cast_raw_list = []\n",
    "crew_raw_list = []\n",
    "\n",
    "# Loop through each movie ID in the dataset and retrieve credits data\n",
    "for movie_id in df[\"id\"]:\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{int(movie_id)}/credits?language=en-US\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            cast = data.get(\"cast\", [])\n",
    "            crew = data.get(\"crew\", [])\n",
    "\n",
    "            cast_count_list.append(len(cast))\n",
    "            crew_count_list.append(len(crew))\n",
    "            cast_raw_list.append(json.dumps(cast))  # Store raw JSON string\n",
    "            crew_raw_list.append(json.dumps(crew))\n",
    "        else:\n",
    "            # Handle API error gracefully\n",
    "            cast_count_list.append(None)\n",
    "            crew_count_list.append(None)\n",
    "            cast_raw_list.append(None)\n",
    "            crew_raw_list.append(None)\n",
    "    except Exception:\n",
    "        # Handle other unexpected errors\n",
    "        cast_count_list.append(None)\n",
    "        crew_count_list.append(None)\n",
    "        cast_raw_list.append(None)\n",
    "        crew_raw_list.append(None)\n",
    "\n",
    "    time.sleep(0.25)  # Respect API rate limits\n",
    "\n",
    "# Add new columns to the original DataFrame\n",
    "df[\"cast_count\"] = cast_count_list\n",
    "df[\"crew_count\"] = crew_count_list\n",
    "df[\"cast\"] = cast_raw_list\n",
    "df[\"crew\"] = crew_raw_list\n",
    "\n",
    "# Save the updated CSV file\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30eca6-d248-4a57-91f5-a6254c2a7537",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c78ca-816d-4535-aeaf-8c79a4258386",
   "metadata": {},
   "source": [
    "Based on the [TMDB API documentation for movie keywords](https://developer.themoviedb.org/reference/movie-keywords), the `keywords` field was added.  \n",
    "\n",
    "It contains thematic tags such as `espionage`, `based on true story`, etc., useful for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f1d9a3f-23d9-4529-8325-9fdbeeff0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store keywords for each movie\n",
    "keywords_data = []\n",
    "\n",
    "# Loop through each movie ID\n",
    "for movie_id in df[\"id\"]:\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{int(movie_id)}/keywords\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            keywords = [k[\"name\"] for k in data.get(\"keywords\", [])]\n",
    "            keywords_data.append(keywords)\n",
    "        else:\n",
    "            keywords_data.append(None)\n",
    "    except Exception as e:\n",
    "        keywords_data.append(None)\n",
    "\n",
    "    time.sleep(0.25)  # Avoid rate limiting\n",
    "\n",
    "# Add keywords as a new column\n",
    "df[\"keywords\"] = keywords_data\n",
    "\n",
    "# Save the updated CSV file\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a49011-e73b-4cc3-8d55-04464ad4cb85",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d05ff24-630a-4a65-ba30-82879c425ec6",
   "metadata": {},
   "source": [
    "Based on the [TMDB API documentation for movie reviews](https://developer.themoviedb.org/reference/movie-reviews), the `reviews` field was added.\n",
    "\n",
    "Although the TMDB database provides relatively few user reviews, we choose to retain the available review data, as it may carry signals that correlate with a movie’s rating. This feature is included with appropriate handling of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1484553-358b-4618-9cb6-3835cb809f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store review lists per movie\n",
    "review_data = []\n",
    "\n",
    "# Loop through each movie ID\n",
    "for movie_id in df[\"id\"]:\n",
    "    all_reviews = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        url = f\"https://api.themoviedb.org/3/movie/{int(movie_id)}/reviews?language=en-US&page={page}\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                results = data.get(\"results\", [])\n",
    "                \n",
    "                if not results:\n",
    "                    break\n",
    "\n",
    "                for item in results:\n",
    "                    author = item.get(\"author\", \"unknown\")\n",
    "                    content = item.get(\"content\", \"\").replace(\"\\r\", \" \").replace(\"\\n\", \" \").strip()\n",
    "                    all_reviews.append(f\"{author}: {content}\")\n",
    "                \n",
    "                if page >= data.get(\"total_pages\", 1):\n",
    "                    break\n",
    "                else:\n",
    "                    page += 1\n",
    "                    time.sleep(0.3)  # 控制速率\n",
    "            else:\n",
    "                all_reviews = None\n",
    "                break\n",
    "        except Exception as e:\n",
    "            all_reviews = None\n",
    "            break\n",
    "\n",
    "    review_data.append(all_reviews if all_reviews else None)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "df[\"reviews_TMDB\"] = review_data\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d8ae37-db7d-4751-9d3c-578c0f9d3bf2",
   "metadata": {},
   "source": [
    "### Watch Providers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9baaf8a-7d3e-4210-b1d9-c7442ae1282e",
   "metadata": {},
   "source": [
    "Based on the [TMDB API documentation for watch providers](https://developer.themoviedb.org/reference/movie-watch-providers), the `watch_providers` field was added.  \n",
    "\n",
    "It contains information about where a movie can be streamed, rented, or purchased across different countries and platforms (e.g., Netflix, Apple TV, Amazon). May be weakly correlated with rating due to platform selection bias and audience exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4761cd1a-41ed-45ee-942e-0ceeaa4da752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store watch provider info\n",
    "watch_provider_data = []\n",
    "\n",
    "# Loop through movie IDs\n",
    "for movie_id in df[\"id\"]:\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{int(movie_id)}/watch/providers\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Store full country-wise results for now\n",
    "            watch_provider_data.append(data.get(\"results\", {}))\n",
    "        else:\n",
    "            watch_provider_data.append(None)\n",
    "    except Exception as e:\n",
    "        watch_provider_data.append(None)\n",
    "\n",
    "    time.sleep(0.25)  # Prevent hitting the API rate limit\n",
    "\n",
    "# Add the data to the dataframe\n",
    "df[\"watch_providers\"] = watch_provider_data\n",
    "\n",
    "# Save the updated CSV file\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7389b37-777e-4621-8f57-6d24e485e76f",
   "metadata": {},
   "source": [
    "### External IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba39e87-5343-4353-b80a-ee441d421335",
   "metadata": {},
   "source": [
    "Based on the [TMDB API documentation for movie external IDs](https://developer.themoviedb.org/reference/movie-external-ids), the `external_ids` field was appended to the dataset. \n",
    "\n",
    "It includes external reference identifiers such as IMDb ID, Wikidata ID, and social media handles (Facebook, Instagram, Twitter).\n",
    "\n",
    "* **IMDb ID** will later be used to scrape additional features including IMDb Rating, IMDb Vote Count, and Metascore.\n",
    "\n",
    "* **Wikidata ID** will be used to scrape awards and nominations through structured queries.\n",
    "\n",
    "* Social media accounts (e.g., number of followers, engagement, posting activity) may serve as indirect indicators of marketing investment. However, due to the high cost of data collection, restricted access, and their relatively low expected contribution to rating prediction, we chose not to include them at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1af2d6f6-2925-462f-a96a-7e9b4e1400f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold external IDs for each movie\n",
    "external_ids_data = []\n",
    "\n",
    "# Loop through each movie ID\n",
    "for movie_id in df[\"id\"]:\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{int(movie_id)}/external_ids\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            external_ids_data.append(data)  # Store full dict (includes IMDb, Facebook, Twitter, etc.)\n",
    "        else:\n",
    "            external_ids_data.append(None)\n",
    "    except Exception:\n",
    "        external_ids_data.append(None)\n",
    "\n",
    "    time.sleep(0.25)  # Avoid hitting rate limit\n",
    "\n",
    "# Add as a new column to the dataframe\n",
    "df[\"external_ids\"] = external_ids_data\n",
    "\n",
    "# Save the updated CSV file\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1340d87-f1b7-4022-bc76-7700f13f3d90",
   "metadata": {},
   "source": [
    "## Enrich Person-level Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35f10c-19e6-4484-9871-670025a5856d",
   "metadata": {},
   "source": [
    "### Extract and Structure Top Cast Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705e475-3182-4a24-9eac-0c1f6cac2339",
   "metadata": {},
   "source": [
    "Only the top 5 actors are included, as they usually represent the core cast with the greatest influence on audience perception and overall film quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "933fc08d-2266-45ff-a45a-f0013184809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded cast columns have been saved to sample.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the original dataset\n",
    "sample = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "# Define the number of top cast members to retain\n",
    "MAX_CAST = 5\n",
    "\n",
    "# Fields to extract from each actor (excluding 'order')\n",
    "BASE_FIELDS = [\"id\", \"name\", \"gender\", \"popularity\"]\n",
    "\n",
    "# Create new columns in the DataFrame for each actor and field\n",
    "for idx in range(1, MAX_CAST + 1):\n",
    "    for field in BASE_FIELDS:\n",
    "        sample[f\"actor_{idx}_{field}\"] = None\n",
    "\n",
    "# Loop through each row to extract top 5 cast members' data\n",
    "for row_idx, cast_json in sample[\"cast\"].items():\n",
    "    try:\n",
    "        cast_list = json.loads(cast_json)\n",
    "    except (TypeError, json.JSONDecodeError):\n",
    "        cast_list = []\n",
    "\n",
    "    # Sort cast by 'order' and keep the top N\n",
    "    top_cast = sorted(cast_list, key=lambda x: x.get(\"order\", 999))[:MAX_CAST]\n",
    "\n",
    "    # Populate the new columns with selected fields\n",
    "    for pos, actor in enumerate(top_cast, start=1):\n",
    "        for field in BASE_FIELDS:\n",
    "            sample.at[row_idx, f\"actor_{pos}_{field}\"] = actor.get(field)\n",
    "\n",
    "# Save the updated CSV file\n",
    "sample.to_csv(\"sample.csv\", index=False)\n",
    "print(\"Expanded cast columns have been saved to sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6a2c0-c75f-4e98-a6d3-7d3db3e4f71b",
   "metadata": {},
   "source": [
    "### Extract and Structure Top Crew Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff2963-0aff-4797-850e-3a04a4500b76",
   "metadata": {},
   "source": [
    "To prioritize the most influential crew members for predicting a movie’s rating, we focus on six key roles that are most commonly associated with major film awards, roles that most significantly influence a film’s quality and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9db5403a-b7df-45f3-89d7-b9aad0380cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset\n",
    "sample = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "# Award-driven priority crew jobs and limits per job\n",
    "priority_jobs = {\n",
    "    \"Director\": 1,                 # Best Director\n",
    "    \"Writer\": 1,                   # Best Original / Adapted Screenplay\n",
    "    \"Producer\": 1,                 # Best Picture (producer credit)\n",
    "    \"Director of Photography\": 1,  # Best Cinematography\n",
    "    \"Editor\": 1,                   # Best Film Editing\n",
    "    \"Original Music Composer\": 1   # Best Original Score\n",
    "}\n",
    "\n",
    "BASE_FIELDS = [\"id\", \"name\", \"gender\", \"popularity\"]\n",
    "\n",
    "def prefix(job: str) -> str:\n",
    "    \"\"\"Convert job title to a safe lowercase prefix for column names.\"\"\"\n",
    "    return job.lower().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "# Pre-create empty columns for each (job, idx, field)\n",
    "for job, max_keep in priority_jobs.items():\n",
    "    p = prefix(job)\n",
    "    for idx in range(1, max_keep + 1):\n",
    "        for field in BASE_FIELDS:\n",
    "            sample[f\"{p}_{idx}_{field}\"] = None\n",
    "\n",
    "# Parse each crew JSON list, keep only priority jobs, fill columns\n",
    "for row_idx, crew_json in sample[\"crew\"].items():\n",
    "    try:\n",
    "        crew_list = json.loads(crew_json)\n",
    "    except (TypeError, json.JSONDecodeError):\n",
    "        crew_list = []\n",
    "\n",
    "    # Group crew by job\n",
    "    grouped = {}\n",
    "    for member in crew_list:\n",
    "        job_name = member.get(\"job\")\n",
    "        if job_name in priority_jobs:\n",
    "            grouped.setdefault(job_name, []).append(member)\n",
    "\n",
    "    # Fill DataFrame up to N per job\n",
    "    for job_name, max_keep in priority_jobs.items():\n",
    "        members = grouped.get(job_name, [])[:max_keep]\n",
    "        p = prefix(job_name)\n",
    "        for idx, person in enumerate(members, start=1):\n",
    "            for field in BASE_FIELDS:\n",
    "                sample.at[row_idx, f\"{p}_{idx}_{field}\"] = person.get(field)\n",
    "\n",
    "# Save the updated CSV file\n",
    "sample.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425eb287-1797-43d1-b15b-a04e3e38dd47",
   "metadata": {},
   "source": [
    "### Use cast id to get more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c8e60d8-4786-443f-b032-3d377003ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset\n",
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "bearer_token = (\n",
    "    \"eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI3YjQ3ODJjOWIwYTVhYmZjNzg5YjJiNzljZmFiMjYwMSIsIm5iZiI6MTc0Mzc1NDE0Mi43NjQ5OTk5LCJzdWIiOiI2N2VmOTM5ZTBjNzkxYmViNTdhY2Y1YWUiLCJzY29wZXMiOlsiYXBpX3JlYWQiXSwidmVyc2lvbiI6MX0.2FmX4__p3XQQi5IagAJ1Csa-3WvL67-msP6158CbsHs\"\n",
    ")\n",
    "\n",
    "BASE_URL  = \"https://api.themoviedb.org/3/person/{}?language=en-US\"\n",
    "HEADERS   = {\"accept\": \"application/json\", \"Authorization\": f\"Bearer {bearer_token}\"}\n",
    "SLEEP_SEC = 0.25\n",
    "\n",
    "# Cache to avoid duplicate network calls\n",
    "\n",
    "detail_cache = {}\n",
    "\n",
    "def fetch_person(pid: int) -> dict:\n",
    "    \"\"\"Return TMDB person-details JSON (empty dict if any error).\"\"\"\n",
    "    if pd.isna(pid):\n",
    "        return {}\n",
    "    if pid in detail_cache:\n",
    "        return detail_cache[pid]\n",
    "\n",
    "    try:\n",
    "        r = requests.get(BASE_URL.format(int(pid)), headers=HEADERS, timeout=10)\n",
    "        detail_cache[pid] = r.json() if r.status_code == 200 else {}\n",
    "    except Exception:\n",
    "        detail_cache[pid] = {}\n",
    "\n",
    "    time.sleep(SLEEP_SEC)\n",
    "    return detail_cache[pid]\n",
    "\n",
    "actor_id_cols = [c for c in df.columns if c.startswith(\"actor_\") and c.endswith(\"_id\")]\n",
    "\n",
    "# Expand actor_N_details columns (N = 1…5)\n",
    "for id_col in actor_id_cols:\n",
    "    details_col = id_col.replace(\"_id\", \"_details\")\n",
    "    df[details_col] = df[id_col].apply(\n",
    "        lambda x: json.dumps(fetch_person(x), ensure_ascii=False)\n",
    "    )\n",
    "\n",
    "# Save the updated CSV file\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723213f9-64e2-4eec-89a9-b232d72a64a3",
   "metadata": {},
   "source": [
    "#### Extract biography column for actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84501086-1661-474a-a87b-b63e408f0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "detail_cols = [\n",
    "    c for c in df.columns\n",
    "    if c.startswith(\"actor_\") and c.endswith(\"_details\")\n",
    "]\n",
    "\n",
    "def extract_bio(detail_json):\n",
    "    \"\"\"Return biography string or None.\"\"\"\n",
    "    if pd.isna(detail_json) or detail_json == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(detail_json).get(\"biography\")\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return None\n",
    "\n",
    "for col in detail_cols:\n",
    "    bio_col = col.replace(\"_details\", \"_biography\")\n",
    "    df[bio_col] = df[col].apply(extract_bio)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4dc8c-4043-4c1b-8341-3a47aa98e1ce",
   "metadata": {},
   "source": [
    "### Use crew id to get more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36a690c9-f821-4d17-b7ce-26f85719cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "bearer_token = (\n",
    "    \"eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI3YjQ3ODJjOWIwYTVhYmZjNzg5YjJiNzljZmFiMjYwMSIsIm5iZiI6MTc0Mzc1NDE0Mi43NjQ5OTk5LCJzdWIiOiI2N2VmOTM5ZTBjNzkxYmViNTdhY2Y1YWUiLCJzY29wZXMiOlsiYXBpX3JlYWQiXSwidmVyc2lvbiI6MX0.2FmX4__p3XQQi5IagAJ1Csa-3WvL67-msP6158CbsHs\"\n",
    ")\n",
    "HEADERS = {\"accept\": \"application/json\",\n",
    "           \"Authorization\": f\"Bearer {bearer_token}\"}\n",
    "BASE_URL = \"https://api.themoviedb.org/3/person/{}?language=en-US\"\n",
    "SLEEP = 0.25            # ≤ 4 req/s (safe for TMDB)\n",
    "\n",
    "# PERSON-DETAILS FETCHER (with simple cache)\n",
    "cache = {}\n",
    "\n",
    "def get_person(pid):\n",
    "    if pd.isna(pid):\n",
    "        return {}\n",
    "    pid = int(pid)\n",
    "    if pid in cache:\n",
    "        return cache[pid]\n",
    "    try:\n",
    "        r = requests.get(BASE_URL.format(pid), headers=HEADERS, timeout=10)\n",
    "        cache[pid] = r.json() if r.status_code == 200 else {}\n",
    "    except Exception:\n",
    "        cache[pid] = {}\n",
    "    time.sleep(SLEEP)\n",
    "    return cache[pid]\n",
    "\n",
    "# IDENTIFY ALL CREW-ID COLUMNS\n",
    "crew_id_cols = []\n",
    "for job, n in priority_jobs.items():\n",
    "    p = prefix(job)                       # e.g. director_, writer_\n",
    "    for i in range(1, n + 1):\n",
    "        col = f\"{p}_{i}_id\"\n",
    "        if col in df.columns:             # cast columns are actor_*, ignored\n",
    "            crew_id_cols.append(col)\n",
    "\n",
    "# CREATE *_details COLUMNS\n",
    "for id_col in crew_id_cols:\n",
    "    details_col = id_col.replace(\"_id\", \"_details\")\n",
    "    # only fetch where details col is missing to save API quota\n",
    "    df[details_col] = df[id_col].apply(\n",
    "        lambda x: json.dumps(get_person(x), ensure_ascii=False)\n",
    "    )\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc5fe22-075c-44e1-9a88-d5dbb3bb293b",
   "metadata": {},
   "source": [
    "#### Extract biography collumn for crews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5a442f3-4521-4d3a-9533-1d4d2448b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def extract_bio(js):\n",
    "    if pd.isna(js) or js == \"\": \n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(js).get(\"biography\")\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return None\n",
    "\n",
    "crew_detail_cols = [c for c in df.columns \n",
    "                    if c.endswith(\"_details\") and not c.startswith(\"actor_\")]\n",
    "\n",
    "for col in crew_detail_cols:\n",
    "    df[col.replace(\"_details\", \"_biography\")] = df[col].apply(extract_bio)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c9407-7335-4bac-943a-e4bb59c60cbe",
   "metadata": {},
   "source": [
    "## Enrich Enrich External Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcbed8f-86da-4e40-9f65-ed2a5fddf49c",
   "metadata": {},
   "source": [
    "### Clean the External ID Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998580f-b495-4281-bbd7-441d1f87e480",
   "metadata": {},
   "source": [
    "In this step, we retain only the IMDb and Wikidata IDs, as they provide access to relevant information such as ratings and awards. Social media IDs (Facebook, Instagram, Twitter) are excluded because their added value for rating prediction is likely limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64cf45a7-fc7a-4665-b19d-c0faa172f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def to_dict(x):\n",
    "    if pd.isna(x) or x == \"\":\n",
    "        return {}\n",
    "    if isinstance(x, dict):\n",
    "        return x\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "df[\"imdb_id\"] = df[\"external_ids\"].apply(lambda x: to_dict(x).get(\"imdb_id\"))\n",
    "df[\"wikidata_id\"] = df[\"external_ids\"].apply(lambda x: to_dict(x).get(\"wikidata_id\"))\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d34fba0-f351-4309-b030-a6b51fc2298d",
   "metadata": {},
   "source": [
    "### Extract IMDB Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b1aaa2-cde8-42cf-97ab-6316cd9a5bbb",
   "metadata": {},
   "source": [
    "In this step, we extract three key features from IMDb:\n",
    "\n",
    "* `imdb_rating` captures the general public’s evaluation of the film, providing an external benchmark to TMDB ratings.\n",
    "\n",
    "* `imdb_votes` reflects the popularity of a movie among viewers, which often correlates with cultural impact or marketing reach.\n",
    "\n",
    "* `imdb_metascore` introduces a critical perspective, as it aggregates reviews from professional critics. This feature can help balance user-driven ratings with expert evaluations.\n",
    "\n",
    "These three metrics together offer a more comprehensive view of a movie’s reception, which is valuable for improving the accuracy of our rating prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0283590-ffc4-458f-bbc3-d4902a12bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, requests, re, json, time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "df = pd.read_csv(\"sample.csv\") \n",
    "\n",
    "UA = {\"User-Agent\":\n",
    "      \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "      \"Chrome/125.0 Safari/537.36\",\n",
    "      \"Accept-Language\": \"en-US,en;q=0.5\"}\n",
    "BASE = \"https://www.imdb.com/title/{}/\"\n",
    "SLEEP = 0.5\n",
    "cache = {}\n",
    "\n",
    "def fetch_html(imdb_id):\n",
    "    \"\"\"Download page; if redirected to 'consent' once, follow the link.\"\"\"\n",
    "    r = requests.get(BASE.format(imdb_id), headers=UA, timeout=10)\n",
    "    # If IMDb shows a EU consent page (title 'consentstv'), follow the continue link\n",
    "    if \"consent\" in r.url and \"continue\" in r.text.lower():\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        cont = soup.find(\"a\", href=True)\n",
    "        if cont and cont[\"href\"].startswith(\"/title/\"):\n",
    "            r = requests.get(\"https://www.imdb.com\" + cont[\"href\"], headers=UA, timeout=10)\n",
    "    return r.text\n",
    "\n",
    "def scrape(imdb_id):\n",
    "    if pd.isna(imdb_id):          # empty cell\n",
    "        return None, None, None\n",
    "    if imdb_id in cache:\n",
    "        return cache[imdb_id]\n",
    "\n",
    "    rating = votes = metascore = None\n",
    "    try:\n",
    "        html = fetch_html(imdb_id)\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        # rating & votes from JSON-LD\n",
    "        ld_tag = soup.find(\"script\", type=\"application/ld+json\")\n",
    "        if ld_tag:\n",
    "            try:\n",
    "                data = json.loads(ld_tag.string)\n",
    "                agg = data.get(\"aggregateRating\", {})\n",
    "                rating = float(agg.get(\"ratingValue\")) if agg.get(\"ratingValue\") else None\n",
    "                votes  = int(agg.get(\"ratingCount\"))  if agg.get(\"ratingCount\") else None\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "\n",
    "        # metascore\n",
    "        score = soup.select_one(\"span.score-meta\")\n",
    "        if score and score.text.strip().isdigit():\n",
    "            metascore = int(score.text.strip())\n",
    "        else:\n",
    "            alt = soup.select_one('[data-testid=\"metacritic-score-box\"]')\n",
    "            if alt and re.search(r\"\\d+\", alt.text):\n",
    "                metascore = int(re.search(r\"\\d+\", alt.text).group())\n",
    "            else:\n",
    "                m = re.search(r'\"metacritic\"\\s*:\\s*{[^}]*?\"score\"\\s*:\\s*(\\d+)', html)\n",
    "                if m:\n",
    "                    metascore = int(m.group(1))\n",
    "\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    cache[imdb_id] = (rating, votes, metascore)\n",
    "    time.sleep(SLEEP)\n",
    "    return rating, votes, metascore\n",
    "\n",
    "df[[\"imdb_rating\", \"imdb_votes\", \"imdb_metascore\"]] = (\n",
    "    df[\"imdb_id\"]\n",
    "      .apply(lambda x: pd.Series(scrape(x),\n",
    "                                 index=[\"imdb_rating\", \"imdb_votes\", \"imdb_metascore\"]))\n",
    ")\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf878b3f-ad27-426d-a457-425edd3383e0",
   "metadata": {},
   "source": [
    "### Extract Wikidata features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73934c-ca26-47d2-a728-85e43d7c1999",
   "metadata": {},
   "source": [
    "While Wikidata contains many other attributes (e.g., release date, director, language), these have already been captured in the TMDB dataset.\n",
    "\n",
    "In this step, we focus solely on two key features from Wikidata: the number and names of awards received (`award_count`, `award_names`) and nominations (`nominated_count`, `nominated_names`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a97615fa-df2e-4091-8701-5d63d7710f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add four columns to sample.csv, based on the Wikidata ID in column\n",
    "`wikidata_id`.\n",
    "\n",
    "new columns:\n",
    "    award_count          – distinct awards won  (P166)\n",
    "    award_names          – “; ”-joined English labels of those awards\n",
    "    nominated_count      – distinct award nominations (P1411)\n",
    "    nominated_names      – “; ”-joined English labels of those nominations\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "API = \"https://www.wikidata.org/wiki/Special:EntityData/{}.json\"\n",
    "LABEL_API = \"https://www.wikidata.org/w/api.php\"\n",
    "SLEEP = 0.4\n",
    "item_cache, label_cache = {}, {}\n",
    "\n",
    "def get_entity(qid):\n",
    "    if qid in item_cache:                       # cached JSON\n",
    "        return item_cache[qid]\n",
    "    try:\n",
    "        data = requests.get(API.format(qid), timeout=10).json()\n",
    "        item_cache[qid] = data\n",
    "        time.sleep(SLEEP)\n",
    "        return data\n",
    "    except Exception:\n",
    "        item_cache[qid] = {}\n",
    "        return {}\n",
    "\n",
    "def get_labels(qids):\n",
    "    \"\"\"Return dict {qid: en_label}, fetching uncached items in bulk.\"\"\"\n",
    "    need = [q for q in qids if q not in label_cache]\n",
    "    if need:\n",
    "        params = {\n",
    "            \"action\": \"wbgetentities\",\n",
    "            \"ids\": \"|\".join(need),\n",
    "            \"format\": \"json\",\n",
    "            \"props\": \"labels\",\n",
    "            \"languages\": \"en\"\n",
    "        }\n",
    "        try:\n",
    "            obj = requests.get(LABEL_API, params=params, timeout=10).json()\n",
    "            for q, ent in obj.get(\"entities\", {}).items():\n",
    "                label_cache[q] = ent.get(\"labels\", {}).get(\"en\", {}).get(\"value\")\n",
    "            time.sleep(SLEEP)\n",
    "        except Exception:\n",
    "            for q in need:\n",
    "                label_cache[q] = None\n",
    "    return {q: label_cache.get(q) for q in qids}\n",
    "\n",
    "def extract_awards(qid):\n",
    "    data = get_entity(qid)\n",
    "    claims = data.get(\"entities\", {}).get(qid, {}).get(\"claims\", {})\n",
    "    won = {snak[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "           for snak in claims.get(\"P166\", [])        # award received\n",
    "           if snak.get(\"mainsnak\", {}).get(\"datavalue\")}\n",
    "    nom = {snak[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "           for snak in claims.get(\"P1411\", [])       # nominated for\n",
    "           if snak.get(\"mainsnak\", {}).get(\"datavalue\")}\n",
    "    labels = get_labels(won | nom)\n",
    "    won_names = sorted(filter(None, (labels[q] for q in won)))\n",
    "    nom_names = sorted(filter(None, (labels[q] for q in nom)))\n",
    "    return (\n",
    "        len(won_names), \"; \".join(won_names) if won_names else None,\n",
    "        len(nom_names), \"; \".join(nom_names) if nom_names else None\n",
    "    )\n",
    "\n",
    "df[[\"award_count\", \"award_names\",\n",
    "    \"nominated_count\", \"nominated_names\"]] = (\n",
    "    df[\"wikidata_id\"]\n",
    "      .apply(lambda x: pd.Series(extract_awards(str(x)) if pd.notna(x) else (None, None, None, None),\n",
    "                                 index=[\"award_count\", \"award_names\",\n",
    "                                        \"nominated_count\", \"nominated_names\"]))\n",
    ")\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137dd414-bbf5-48a9-ae72-3466805cf941",
   "metadata": {},
   "source": [
    "## Feature Cleaning & Transformation\n",
    "\n",
    "The above steps have acquired all the potentially useful features in across TMDB and external platforms, so the next step will be make the output sheet cleaner for futher fine-tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff0f70-5855-43a5-bcfd-8998897de0fc",
   "metadata": {},
   "source": [
    "### Transform to Binary Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4edba98-7b77-4321-aa54-052026452084",
   "metadata": {},
   "source": [
    "#### backdrop_path & poster_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68ecb48e-96fd-49f8-9bd8-53a95b7f1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "# backdrop_path → has_backdrop\n",
    "df[\"has_backdrop\"] = df[\"backdrop_path\"].notna() & df[\"backdrop_path\"].str.strip().ne(\"\")\n",
    "\n",
    "# poster_path → has_poster\n",
    "df[\"has_poster\"] = df[\"poster_path\"].notna() & df[\"poster_path\"].str.strip().ne(\"\")\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb5f013-4368-4368-b928-3510be2dbdcd",
   "metadata": {},
   "source": [
    "#### homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01f22b5c-6cf3-4336-88d2-4d64017534ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "df[\"has_homepage\"] = df[\"homepage\"].apply(lambda x: True if pd.notna(x) and x.strip() != \"\" else False)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef8245-bda6-41f7-bb17-44cf34ba50ff",
   "metadata": {},
   "source": [
    "### Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6bdb52-c04d-4e2f-9e43-02e8c5c636f5",
   "metadata": {},
   "source": [
    "#### belongs_to_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6367c0c1-3009-43de-a9a4-e721e8662ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def extract_collection_name(val):\n",
    "    if pd.isna(val) or val.strip() == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        parsed = ast.literal_eval(val)\n",
    "        return parsed.get(\"name\")\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "df[\"collection_name\"] = df[\"belongs_to_collection\"].apply(extract_collection_name)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a0c011-d6c0-4bac-816a-b6fabb56991a",
   "metadata": {},
   "source": [
    "#### genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f823dc9e-6fde-49cf-a450-78070359e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def extract_genre_names(val):\n",
    "    if pd.isna(val) or val.strip() == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        genre_list = ast.literal_eval(val)\n",
    "        if isinstance(genre_list, list):\n",
    "            names = [g[\"name\"] for g in genre_list if \"name\" in g]\n",
    "            return \", \".join(names)\n",
    "        return None\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "df[\"genres_names\"] = df[\"genres\"].apply(extract_genre_names)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9d613-8a8b-448f-9e91-23b0ddc686bd",
   "metadata": {},
   "source": [
    "#### origin_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0dec56f8-2253-40de-bf4d-6f566d82fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycountry in /Users/qiuqiuyang/Anaconda/anaconda3/lib/python3.9/site-packages (24.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycountry\n",
    "import pycountry\n",
    "\n",
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def code_to_country(code):\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=code)\n",
    "        return country.name if country else code\n",
    "    except:\n",
    "        return code\n",
    "\n",
    "def parse_and_convert(val):\n",
    "    if pd.isna(val) or val.strip() == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        country_codes = ast.literal_eval(val)\n",
    "        if not isinstance(country_codes, list):\n",
    "            return None\n",
    "        countries = [code_to_country(c) for c in country_codes]\n",
    "        return \", \".join(countries)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "df[\"origin_countries\"] = df[\"origin_country\"].apply(parse_and_convert)\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e00808-d455-4467-93aa-ddf840b63f69",
   "metadata": {},
   "source": [
    "#### original_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ec45546-eb87-446a-b2fb-66b66b7597fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def code_to_language(code):\n",
    "    try:\n",
    "        lang = pycountry.languages.get(alpha_2=code)\n",
    "        return lang.name if lang else code\n",
    "    except:\n",
    "        return code\n",
    "\n",
    "df[\"original_language_name\"] = df[\"original_language\"].apply(code_to_language)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d401e-8354-47cb-84bb-b8d45f52e451",
   "metadata": {},
   "source": [
    "#### production_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "916f8c1b-5fd8-4724-a97c-f9a876114544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def extract_country_names(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    try:\n",
    "        items = ast.literal_eval(val)\n",
    "        if isinstance(items, list):\n",
    "            names = [item.get(\"name\") for item in items if isinstance(item, dict) and item.get(\"name\")]\n",
    "            return \", \".join(names) if names else None\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "df[\"production_country_names\"] = df[\"production_countries\"].apply(extract_country_names)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6fca14-4594-4aa7-b8d6-ae4100ae121c",
   "metadata": {},
   "source": [
    "#### spoken_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d520b781-92dd-4181-b7e2-bbfb0d0eabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def extract_language_names(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    try:\n",
    "        items = ast.literal_eval(val)\n",
    "        if isinstance(items, list):\n",
    "            names = [item.get(\"english_name\") for item in items if isinstance(item, dict) and item.get(\"english_name\")]\n",
    "            return \", \".join(names) if names else None\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "df[\"spoken_language_names\"] = df[\"spoken_languages\"].apply(extract_language_names)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c3c03-3ec0-4b83-80f1-2c11acd6208a",
   "metadata": {},
   "source": [
    "#### production_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b9933d3-e1d6-4e81-8f62-e7e6aabea20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def extract_company_names(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    try:\n",
    "        items = ast.literal_eval(val)\n",
    "        if isinstance(items, list):\n",
    "            names = [item.get(\"name\") for item in items if isinstance(item, dict) and item.get(\"name\")]\n",
    "            return \", \".join(names) if names else None\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "df[\"production_company_names\"] = df[\"production_companies\"].apply(extract_company_names)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999484f4-8e33-416b-8a41-6e5de6ef6527",
   "metadata": {},
   "source": [
    "#### keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f378ac6f-ff6d-461b-9735-1dd61445b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def clean_keywords(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    try:\n",
    "        keywords = ast.literal_eval(val)\n",
    "        if isinstance(keywords, list):\n",
    "            return \", \".join(str(k) for k in keywords)\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "df[\"keyword_list\"] = df[\"keywords\"].apply(clean_keywords)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8843bca-8a69-46b2-b2dd-72dbb8647d7e",
   "metadata": {},
   "source": [
    "#### watch_providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a0c27cb-9e6c-4734-ba2c-62b71bc859c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def extract_provider_names(val):\n",
    "    if pd.isna(val) or val.strip() == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        data = ast.literal_eval(val)            # dict keyed by country code\n",
    "        if not isinstance(data, dict):\n",
    "            return None\n",
    "        names = []\n",
    "        for country in data.values():           # loop each country's sub-dict\n",
    "            if not isinstance(country, dict):\n",
    "                continue\n",
    "            for cat in (\"flatrate\", \"rent\", \"buy\"):\n",
    "                for provider in country.get(cat, []):\n",
    "                    n = provider.get(\"provider_name\")\n",
    "                    if n:\n",
    "                        names.append(n)\n",
    "        if not names:\n",
    "            return None\n",
    "        return \", \".join(sorted(set(names)))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "df[\"watch_provider_names\"] = df[\"watch_providers\"].apply(extract_provider_names)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b15fd-e743-4633-aa76-ab46296fac0e",
   "metadata": {},
   "source": [
    "#### gender-related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "28ac6f75-e585-4884-9a85-f65f358e47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "# mapping: numeric code → descriptive label\n",
    "gender_map = {\n",
    "    0: \"Not set / not specified\",\n",
    "    1: \"Female\",\n",
    "    2: \"Male\",\n",
    "    3: \"Non-binary\"\n",
    "}\n",
    "\n",
    "# find every column whose name ends with \"_gender\"\n",
    "gender_cols = [c for c in df.columns if c.endswith(\"_gender\")]\n",
    "\n",
    "for col in gender_cols:\n",
    "    label_col = col.replace(\"_gender\", \"_gender_label\")\n",
    "    df[label_col] = df[col].map(gender_map)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903502a7-2418-441e-b01c-0187f27b141e",
   "metadata": {},
   "source": [
    "#### reviews_TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6d315b6-cbd7-43b3-b830-3578d887caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "def clean_reviews(val):\n",
    "    if pd.isna(val) or val.strip() == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        reviews = ast.literal_eval(val)          # \"['user: text', ...]\" → list\n",
    "        texts = []\n",
    "        for r in reviews:\n",
    "            if not isinstance(r, str):\n",
    "                continue\n",
    "            body = r.split(\":\", 1)[-1].strip()\n",
    "            if body:\n",
    "                texts.append(body)\n",
    "        return \" \".join(texts) if texts else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "df[\"reviews_clean\"] = df[\"reviews_TMDB\"].apply(clean_reviews)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e740b-2697-4d19-bd8c-0bd75edadd16",
   "metadata": {},
   "source": [
    "## Column Re-ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef8e41-0dfd-4672-b8eb-0363248a86fb",
   "metadata": {},
   "source": [
    "### Remove Uncleaned and Untransformed Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f33cb1c-42c1-4c46-98fc-5a3ff88e2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"backdrop_path\", \"belongs_to_collection\", \"genres\", \"homepage\", \"origin_country\",\n",
    "    \"original_language\", \"poster_path\", \"production_companies\", \"production_countries\",\n",
    "    \"spoken_languages\", \"cast\", \"crew\", \"keywords\", \"watch_providers\", \"external_ids\",\n",
    "    \"actor_1_details\", \"actor_2_details\", \"actor_3_details\", \"actor_4_details\", \"actor_5_details\",\n",
    "    \"director_1_details\", \"writer_1_details\", \"producer_1_details\",\n",
    "    \"director_of_photography_1_details\", \"editor_1_details\", \"original_music_composer_1_details\",\n",
    "    \"actor_1_gender\", \"actor_2_gender\", \"actor_3_gender\", \"actor_4_gender\", \"actor_5_gender\",\n",
    "    \"director_1_gender\", \"writer_1_gender\", \"producer_1_gender\",\n",
    "    \"director_of_photography_1_gender\", \"editor_1_gender\", \"original_music_composer_1_gender\"\n",
    "]\n",
    "\n",
    "df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3204c0-5621-4e0b-a83e-c718f239e5b4",
   "metadata": {},
   "source": [
    "### Reorder and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c013d504-3cac-4b3b-ada4-53e1d8883d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\")\n",
    "\n",
    "identifiers = [\n",
    "    \"id\", \"imdb_id\", \"wikidata_id\"\n",
    "]\n",
    "\n",
    "basic_info = [\n",
    "    \"title\", \"original_title\", \"tagline\", \"overview\",\n",
    "    \"release_date\", \"status\",\n",
    "]\n",
    "\n",
    "numeric_info = [\n",
    "    \"budget\", \"revenue\", \"runtime\",\n",
    "    \"popularity\", \"vote_average\", \"vote_count\",\n",
    "    \"imdb_rating\", \"imdb_votes\", \"imdb_metascore\", \"novelty\", \n",
    "]\n",
    "\n",
    "flags = [\n",
    "    \"adult\", \"video\", \"has_homepage\", \n",
    "    \"has_backdrop\", \"has_poster\", \n",
    "]\n",
    "\n",
    "language_geo = [\n",
    "    \"original_language_name\", \"origin_countries\",\n",
    "    \"production_country_names\", \"spoken_language_names\",\n",
    "]\n",
    "\n",
    "categorical_text = [\n",
    "    \"collection_name\", \"genres_names\",\n",
    "    \"keyword_list\", \"watch_provider_names\",\n",
    "    \"production_company_names\",\n",
    "]\n",
    "\n",
    "award_cols = [\n",
    "    \"award_count\", \"award_names\",\n",
    "    \"nominated_count\", \"nominated_names\",\n",
    "]\n",
    "\n",
    "count_cols = [\n",
    "    \"cast_count\", \"crew_count\",\n",
    "]\n",
    "\n",
    "review_cols = [\n",
    "    \"reviews_TMDB\",\n",
    "]\n",
    "\n",
    "people_prefixes = [\n",
    "    \"actor\",\n",
    "    \"director\",\n",
    "    \"writer\",\n",
    "    \"producer\",\n",
    "    \"director_of_photography\",\n",
    "    \"editor\",\n",
    "    \"original_music_composer\",\n",
    "]\n",
    "\n",
    "def gather_people_cols(prefix):\n",
    "    pat = re.compile(rf\"^{re.escape(prefix)}_(\\d+)_\")\n",
    "    cols = [c for c in df.columns if c.startswith(prefix + \"_\")]\n",
    "    ordered = []\n",
    "    idx_set = sorted({int(pat.match(c).group(1)) for c in cols if pat.match(c)})\n",
    "    for idx in idx_set:\n",
    "        ordered.extend([c for c in cols if pat.match(c) and int(pat.match(c).group(1)) == idx])\n",
    "    return ordered\n",
    "\n",
    "people_cols_ordered = []\n",
    "for pre in people_prefixes:\n",
    "    people_cols_ordered.extend(gather_people_cols(pre))\n",
    "\n",
    "ordered = (\n",
    "    identifiers\n",
    "    + basic_info\n",
    "    + numeric_info\n",
    "    + flags\n",
    "    + language_geo\n",
    "    + categorical_text\n",
    "    + award_cols\n",
    "    + count_cols\n",
    "    + review_cols\n",
    "    + people_cols_ordered\n",
    ")\n",
    "\n",
    "remaining = [c for c in df.columns if c not in ordered]\n",
    "ordered += remaining\n",
    "\n",
    "df = df[ordered]\n",
    "df.to_csv(\"sample_ordered.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
